% This file was created with JabRef 2.9.2.
% Encoding: UTF8

@INPROCEEDINGS{Hsu1986,
  author = {Peter Y.-T. Hsu and Edward S. Davidson},
  title = {Highly Concurrent Scalar Processing},
  booktitle = {ISCA},
  year = {1986},
  pages = {386-395},
  bibsource = {DBLP, http://dblp.uni-trier.de},
  crossref = {DBLP:conf/isca/1986},
  ee = {http://doi.acm.org/10.1145/17407.17401},
  owner = {bnm},
  timestamp = {2014.02.26}
}

@INPROCEEDINGS{allen1983Concondeptodatdep,
  author = {Allen, John R and Kennedy, Ken and Porterfield, Carrie and Warren,
	Joe},
  title = {{Conversion of control dependence to data dependence}},
  booktitle = {{Proceedings of the 10th ACM SIGACT-SIGPLAN symposium on Principles
	of programming languages}},
  year = {1983},
  pages = {177--189},
  organization = {ACM},
  url = {http://dl.acm.org/citation.cfm?id=567085},
  x-fetchedfrom = {Google Scholar}
}

@OTHER{August1997,
  __markedentry = {[bnm:]},
  abstract = {Predicated execution is a promising architectural feature for exploiting
	instruction-level parallelism in the presence of control flow. Compiling
	for predicated execution involves converting program control flow
	into conditional, or predicated, instructions. This process is known
	as if-conversion. In order to effectively apply if-conversion, one
	must address two major issues: what should be if-converted and when
	the if-conversion should be applied. A compiler&#039;s use of predication
	as a representation is most effective when large amounts of code
	are if-converted and if-conversion is performed early in the compilation
	procedure. On the other hand, the final code generated for a processor
	with predicated execution requires a delicate balance between control
	flow and predication to achieve efficient execution. The appropriate
	balance is tightly coupled with scheduling decisions and detailed
	processor characteristics. This paper presents an effective compilation
	framework that allows the compiler to maximize the benefits of predication
	as a compiler representation while delaying the final balancing of
	control flow and predication to schedule time.},
  author = {David I. August and Wen-mei W. Hwu and Scott A. Mahlke},
  owner = {bnm},
  timestamp = {2014.02.28},
  title = {A Framework for Balancing Control Flow and Predication},
  year = {1997}
}

@INPROCEEDINGS{bringmann1993Speexeexcrecusiwrisup,
  author = {Bringmann, Roger A. and Mahlke, Scott A. and Hank, Richard E. and
	Gyllenhaal, John C. and mei W. Hwu, Wen},
  title = {{Speculative execution exception recovery using write-back suppression.}},
  booktitle = {{MICRO}},
  year = {1993},
  pages = {214--223},
  publisher = {ACM/IEEE},
  abstract = {dblp},
  added-at = {2006-02-13T00:00:00.000+0100},
  date = {2006-02-13},
  interhash = {4574a801d5e469840995980d497a17fb},
  intrahash = {3a977457266877a68822b92f3edc6980},
  keywords = {dblp},
  url = {http://dblp.uni-trier.de/db/conf/micro/micro1993.html#BringmannMHGH93; http://doi.acm.org/10.1145/255235.255290; http://www.bibsonomy.org/bibtex/23a977457266877a68822b92f3edc6980/dblp},
  x-fetchedfrom = {Bibsonomy}
}

@ARTICLE{ferrante1987prodepgraitsuseopt,
  author = {Ferrante, J. and Ottenstein, K. and Warren, J.},
  title = {{The program dependence graph and its use in optimization}},
  journal = {ACM Transactions on Programming Languages and Systems},
  year = {1987},
  volume = {9},
  pages = {319--349},
  number = {3},
  month = {July},
  added-at = {2008-07-07T16:45:32.000+0200},
  biburl = {http://www.bibsonomy.org/bibtex/2fe62c4467e638866e84426f311b6de77/pdeleenh},
  interhash = {f9315bbba231bcbd92210eba221895c4},
  intrahash = {fe62c4467e638866e84426f311b6de77},
  keywords = {imported},
  owner = {pdeleenh},
  timestamp = {2008.05.15},
  x-fetchedfrom = {Bibsonomy}
}

@OTHER{JosephC.H.Park1991,
  abstract = {this paper, however. We have not bothered to include such complications
	in Algorithm DU},
  author = {Joseph C. H. Park, Mike Schlansker},
  owner = {bnm},
  timestamp = {2014.02.26},
  title = {On Predicated Execution},
  year = {1991}
}

@OTHER{JosephP.Brutt,
  abstract = {The CydraTM 5 architecture adds unique support for overlapping successive
	iterations of a loop to a very long instruction word (VLIW) base.
	This architecture allows highly parallel loop execution for a much
	larger class of loops than can be vectorixed, without requiring the
	unrolling of loops usually used by compilers for VLlW machines. This
	paper discusses the Cydra 5 loop scheduling model, the special architectural
	features which support it, and the loop compilation techniques used
	to take full advantage of the architecture. 1.},
  author = {Joseph P. Brutt, Ardent Computer Ttt},
  owner = {bnm},
  timestamp = {2014.02.26},
  title = {Overlapped Loop Support in the Cydra 5}
}

@OTHER{Lengauer1979,
  __markedentry = {[bnm:6]},
  abstract = {A fast algoritbm for finding dominators in a flowgraph is presented.
	The algorithm uses depth-first search and an efficient method of
	computing functions defined on paths in trees. A simple implemen-tation
	of the algorithm runs in O(m log n) time, where m is the number of
	edges and n is the number of vertices in the problem graph. A more
	sophisticated implementation runs in O(ma(m, n)) time, where a(m,
	n) is a functional inverse of Ackermann&#039;s function. Both versions
	of the algorithm were implemented in Algol W, a Stanford University
	version of Algol, and tested on an IBM 370/168. The programs were
	compared with an implementation by Purdom and Moore of a straightforward
	O(mn)-time algorithm, and with ~a bit vector algorithm described
	by Aho and Ullman. The fast algorithm beat the straightforward algorithm
	and the bit vector algorithm on all but the smallest graphs tested.},
  author = {Lengauer, Thomas and Endre, Robert and Jan, Tar},
  owner = {bnm},
  timestamp = {2014.03.03},
  title = {A fast algorithm for finding dominators in a flowgraph},
  year = {1979}
}

@OTHER{1991,
  author = {M. Butler, T. Yeh, Y. Patt, M. Alsup, H. Scales, M.Shebanow},
  booktitle = {Computer Architecture, 1991. The 18th Annual International Symposium
	on},
  doi = {10.1109/ISCA.1991.1021620},
  owner = {bnm},
  pages = {276--286},
  timestamp = {2014.02.25},
  title = {Single instruction stream parallelism is greater than two},
  url = {http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1021620},
  year = {1991}
}

@OTHER{Mahlke1994,
  abstract = {Branch instructions are recognized as a major impediment to exploiting
	instruction level parallelism. Even with sophisticated branch prediction
	techniques, many frequently executed branches remain difficult to
	predict. An architecture supporting predicated execution may allow
	the compiler to remove many of these hard-to-predict branches, reducing
	the number of branch mispredictions and thereby improving performance.
	We present an in-depth analysis of the characteristics of those branches
	which are frequently mispredicted and examine the effectiveness of
	an advanced compiler to eliminate these branches. Over the benchmarks
	studied, an average of 27% of the dynamic branches and 56% of the
	dynamic branch mispredictions are eliminated with predicated execution
	support.},
  author = {Scott A. Mahlke and Richard E. Hank and Roger A. Bringmann and John
	C. Gyllenhaal and David M. Gallagher and Wen-mei W. Hwu},
  owner = {bnm},
  timestamp = {2014.02.25},
  title = {Characterizing the Impact of Predicated Execution on Branch Prediction},
  year = {1994}
}

@OTHER{Quinones2006,
  abstract = {If-conversion transforms control dependencies to data dependencies
	by using a predication mechanism. It is useful to eliminate hard-to-predict
	branches and to reduce the severe performance impact of branch mispredictions.
	However, the use of predicated execution in out-of-order processors
	has to deal with two problems: there can be multiple definitions
	for a single destination register at rename time, and instructions
	with a false predicated consume unnecessary resources. Predicting
	predicates is an effective approach to address both problems. However,
	predicting predicates that come from hard-to-predict branches is
	not beneficial in general, because this approach reverses the if-conversion
	transformation, loosing its potential benefits. In this paper we
	propose a new scheme that dynamically selects which predicates are
	worthy to be predicted, and which one are more effective in its if-converted
	form. We show that our approach significantly outperforms previous
	proposed schemes. Moreover it performs within 5 % of an ideal scheme
	with perfect predicate prediction.},
  author = {Qui√±ones, Eduardo},
  owner = {bnm},
  timestamp = {2014.02.26},
  title = {Selective predicate prediction for out-of-order processors},
  year = {2006}
}

@OTHER{Quinones2007,
  abstract = {If-conversion is a compiler technique that reduces the misprediction
	penalties caused by hard-to-predict branches, transforming control
	dependencies into data dependencies. Although it is globally beneficial,
	it has a negative side-effect because the removal of branches eliminates
	useful correlation information necessary for conventional branch
	predictors. The remaining branches may become harder to predict.
	However, in predicated ISAs with a compare-branch model, the correlation
	information not only resides in branches, but also in compare instructions
	that compute their guarding predicates. When a branch is removed,
	its correlation information is still available in its compare instruction.
	We propose a branch prediction scheme based on predicate prediction.
	It has three advantages: First, since the prediction is not done
	on a branch basis but on a predicate define basis, branch removal
	after if-conversion does not lose any correlation information, so
	accuracy is not degraded. Second, the mechanism we propose permits
	using the computed value of the branch predicate when available,
	instead of the predicted value, thus effectively achieving 100 %
	accuracy on such early-resolved branches. Third, as shown in previous
	work, the selective predicate prediction is a very effective technique
	to implement if-conversion on outof-order processors, since it avoids
	the problem of multiple register definitions and reduces the unnecessary
	resource consumption of nullified instructions. Hence, our approach
	enables a very efficient implementation of if-conversion for an out-of-order
	processor, with almost no additional hard-},
  author = {Qui√±ones, Eduardo and Departament D‚Äôarquitectura De Computadors and
	Gonz√°lez, Antonio and Joan-manuel Parcerisa},
  owner = {bnm},
  timestamp = {2014.02.26},
  title = {Improving branch prediction and predicate execution in out-of-order
	processors},
  year = {2007}
}

@ARTICLE{1989a,
  author = {B. R. Rau and D. W. L. Yen and W. Yen and J. P. Bratt},
  title = {The Cydra 5 departmental supercomputer: design philosophies, decisions,
	and trade-offs},
  journal = {Computer},
  year = {1989},
  volume = {22},
  pages = {12--35},
  number = {1},
  doi = {10.1109/2.19820},
  owner = {bnm},
  timestamp = {2014.02.26},
  url = {http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=19820}
}

@OTHER{ScottA.Mahlke1992,
  abstract = {Predicated execution is an effective technique for dealing with conditional
	branches in application programs. However, there are several problems
	associated with conventional compiler support for predicated execution.
	First, all paths of control are combined into a single path regardless
	of their execution frequency and size with conventional if-conversion
	techniques. Second, speculative execution is difficult to combine
	with predicated execution. In this paper, we propose the use of a
	new structure, referred to as the hyperblock, to overcome these problems.
	The hyperblock is an efficient structure to utilize predicated execution
	for both compile-time optimization and scheduling. Preliminary experimental
	results show that the hyperblock is highly effective for a wide range
	of superscalar and VLIW processors. },
  author = {Scott A. Mahlke, et al.},
  owner = {bnm},
  timestamp = {2014.02.26},
  title = { Effective Compiler Support for Predicated Execution Using the Hyperblock},
  year = {1992}
}

@OTHER{ScottA.Mahlke1992a,
  abstract = {Predicated execution is an effective technique for dealing with conditional
	branches in application programs. However, there are several problems
	associated with conventional compiler support for predicated execution.
	First, all paths of control are combined into a single path regardless
	of their execution frequency and size with conventional if-conversion
	techniques. Second, speculative execution is difficult to combine
	with predicated execution. In this paper, we propose the use of a
	new structure, referred to as the hyperblock, to overcome these problems.
	The hyperblock is an efficient structure to utilize predicated execution
	for both compile-time optimization and scheduling. Preliminary experimental
	results show that the hyperblock is highly effective for a wide range
	of superscalar and VLIW processors. },
  author = {Scott A. Mahlke, et al.},
  owner = {bnm},
  timestamp = {2014.02.27},
  title = { Effective Compiler Support for Predicated Execution Using the Hyperblock},
  year = {1992}
}

@OTHER{Smith1989,
  abstract = {This paper demonstrates that highly-optimized, non-scientific applications
	also contain ample instruction-level concurrency to sustain an execution
	rate of two instructions per clock cycle. However, the cost requirements
	necessary to provide the instruction bandwidth needed by the instructionexecution
	unit make this performance difficult to achieve},
  author = {Michael D. Smith and Johnson, Mike and Mark A. Horowitz},
  owner = {bnm},
  timestamp = {2014.02.25},
  title = {Limits on Multiple Instruction Issue},
  year = {1989}
}

@ARTICLE{Tian2010,
  author = {Tian, Zuwei and Sun, Guang},
  title = {An If-Conversion Algorithm Based on Predication Execution},
  journal = {Information Technology Journal},
  year = {2010},
  volume = {9},
  pages = {984-988},
  number = {5},
  month = {May},
  doi = {10.3923/itj.2010.984.988},
  issn = {1812-5638},
  owner = {bnm},
  publisher = {Science Alert},
  timestamp = {2014.02.26},
  url = {http://dx.doi.org/10.3923/itj.2010.984.988}
}

@OTHER{Wall1991,
  abstract = {research relevant to the design and application of high performance
	scientific computers. We test our ideas by designing, building, and
	using real systems. The systems we build are research prototypes;
	they are not intended to become products. There two other research
	laboratories located in Palo Alto, the Network Systems},
  author = {David W. Wall},
  owner = {bnm},
  timestamp = {2014.02.25},
  title = {Limits of instruction-level parallelism},
  year = {1991}
}

@OTHER{Warter1993,
  abstract = {In this paper we present a set of isomorphic control transformations
	that allow the compiler to apply local scheduling techniques to acyclic
	subgraphs of the control flow graph. Thus, the code motion complexities
	of global scheduling are eliminated. This approach relies on a new
	technique, Reverse If-Conversion (RIC), that transforms scheduled
	If-Converted code back to the control flow graph representation.
	This paper presents the predicate internal representation, the algorithms
	for RIC, and the correctness of RIC. In addition, the scheduling
	issues are addressed and an application to software pipelining is
	presented. 1 Introduction Compilers for processors with instruction
	level parallelism hardware need a large pool of operations to schedule
	from. In processors without support for conditional execution, branches
	present a scheduling barrier that limits the pool of operations to
	the basic block. Since basic blocks tend to have only a few operations,
	global scheduling techniques are ...},
  author = {Nancy J. Warter and Scott A. Mahlke and Wen-mei W. Hwu and B. Ramakrishna
	Rau},
  owner = {bnm},
  timestamp = {2014.02.28},
  title = {Reverse If-Conversion},
  year = {1993}
}

